{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 TensorFlow 进行文本生成\n",
    "\n",
    "## 递归神经网络简介\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "在本节中，我们将创建的模型会根据句子的前一个单词预测句子中下一个单词，从而生成对语言的理解。\n",
    "\n",
    "在先前的实验室中，我们已对网络应用于含有标注的图像数据集。我们将在这里介绍用于学习文本语料库的语言结构的神经网络。\n",
    "\n",
    "我们将从一个小示例开始，使用小型英语语言子集以及包含两个句子的小语料库，该语料库将包含任何神经网络模型需要学习的语言结构。我们将从这里开始构建，可以表示更多真实世界的内容。\n",
    "\n",
    "首先，我们的字典（点击下面的单元，并按住 Shift + Enter 键以执行代码）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dict=['EOS','a','my','sleeps','on','dog','cat','the','bed','floor'] #'EOS' means end of sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们可以创建小语料库以便网络学习语言。我们来一起根据字典中的单词创建几个句子。numpy 数组“X”中的第一个向量表示句子 ['my','cat','sleeps','on','my','bed', 'EOS']。将该数组作为模型，使用句子 ['a', 'dog', 'sleeps', 'on', 'the', 'floor', 'EOS'] 代替 ##FIXME## 向量。将鼠标指针悬停在 [此处](#hint \"The second line should be X=np.array([[2,6,3,4,2,8,0],[1,5,3,4,7,9,0]]),dtype=np.int32)\")可获取提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'dog', 'sleeps', 'on', 'the', 'floor', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #numpy is \"numerical python\" and is used in deep learning mostly for its n-dimensional array\n",
    "X=np.array([[2,6,3,4,2,8,0],[1,5,3,4,7,9,0]],dtype=np.int32) \n",
    "print([small_dict[ind] for ind in X[1,:]]) #Feel free to change 1 to 0 to see the other sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们有了数据，然后需要针对神经网络模型进行构建计算过程。单词是与图像完全不同类型的数据。一张 28X28 的灰度图像被视为一个 28X28 的矩阵，其中每个单元格都表示该像素的“灰度值”。一张 256X256 彩色的图像被视为一个 256X256X3 的[张量](#tensor \"a vector, matrix, or any other *block* of n-dimensional data\") ，其中每个单元格都包含每个像素的“红色度”、“绿色度”和“蓝色度”。\n",
    "\n",
    "对图像进行分类时，我们使用 TensorFlow（或任何其他框架）来说明该输入张量如何流向概率向量。\n",
    "\n",
    "另外，单词也必须先转换为张量，然后才能将它们用作输入。对于此示例，我们将使用“独热编码”，其中每个单词都将由一个包含一个“1”且其余全部为 0 的向量表示。这些向量将成为字典的长度，其中包含一个位于唯一位置的“1”，具体取决于每个单词。\n",
    "\n",
    "![](images/one-hot.PNG)\n",
    "\n",
    "为了便于理解，我们将运行 TensorFlow [会话](#sess \"where computational graphs described in TensorFlow are run\") ，将我们的输入数据转换为独热编码并对其进行可视化。通过 Tensorflow 的 embedding_lookup 和 unstack 函数，可以很容易地完成此操作。对于独热编码，我们可以向 embedding_lookup 传递一个 [单位矩阵](#idmat \"A matrix with ones in the diagonal and zeros everywhere else\")，其中包含字典和输入数据集的长度。此操作可以在训练会话过程中完成，但我们在此处将它分离出来，以便更好地对输入实现可视化。\n",
    "\n",
    "为了提醒我们使用的英语语言子集有多小，请将 ##FIXME## 替换为字典的长度。将鼠标指针悬停在 [此处](#dict_length \"Replace ##FIXME## in np.identity with len(small_dict).\")可获取提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 6 3 4 2 8 0]\n",
      " [1 5 3 4 7 9 0]]\n",
      "one-hot encoded inputs\n",
      "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "shape of the input\n",
      "(2, 7, 10)\n",
      "reshaped input for training\n",
      "[[array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]), array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]), array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "tf.reset_default_graph()\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        result=tf.nn.embedding_lookup(np.identity(10), X).eval()  #单位矩阵取某一行作为独热编码\n",
    "        example_input=sess.run([tf.unstack(result,X.shape[1],1)])\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "print('one-hot encoded inputs')\n",
    "print(result)\n",
    "print('shape of the input')\n",
    "print(result.shape)\n",
    "print('reshaped input for training')\n",
    "print(example_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions we ended up with are (x, y, z) where:    \n",
    "```x = The number of sentences in our corpus  \n",
    "y = The number of words in each sentence  \n",
    "z = The number of words in our corpus ```\n",
    "\n",
    "我们有了自己的数据！\n",
    "\n",
    "回想一下，神经网络一开始使用随机值填充。通过应用数据，网络“学会”了创建从输入到输出的准确映射。\n",
    "\n",
    "\n",
    "### The Word Generation Workflow\n",
    "\n",
    "我们的图像分类网络根据图像输入来输出标签预测。我们的语言处理网络将根据先前输入的单词来输出下一个单词。\n",
    "\n",
    "例如，让我们选择一个句子，然后尝试自己完成该操作（请尽量不要阅读后面的内容）：\n",
    "\n",
    "我们的句子以单词“My”开头\n",
    "\n",
    "通过使用包含所有您知道的单词的字典以及您在生活中观察到的模式，什么单词可能会出现在单词“My”之后？\n",
    "\n",
    "非常好，您已进行了猜测，然后会发现第二个词是“friend”。\n",
    "\n",
    "您对这个句子有了进一步的了解，并且可以使用前“两个”单词猜测第三个单词。\n",
    "\n",
    "接下来，您会了解到第三个单词是“went”，您会比较猜测的误差,然后再次猜测。与刚开始的时候相比，您是否对这个句子的结构有了更多的了解？如果这是您看到的第一个或第一千个句子，您可能还知道所有句子结构的更多信息。\n",
    "\n",
    "这是神经网络学习语言的一种方式，此类型的网络称为**递归神经网络 (RNN)**。如果有足够的时间和足够大的数据集，它们可以学习所有类型的语言语法：“主语”如何与“动词”相关、标点符号通常会在何时出现等。它们通过减少所预测的下一个单词和语料库中实际的下一个单词之间的误差来进行学习。RNN 被构造为“记住”引发预测的单词。\n",
    "\n",
    "通过使用只有一层的最简单的 RNN网络，看看从两个句子中我们能学到这 8 个单词间怎样的关系。\n",
    "\n",
    "Start with 10 epochs by replacing the ##FIXME## below with the number 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iteration: ', 0, ' loss: ', 2.3385096)\n",
      "('iteration: ', 5, ' loss: ', 1.755022)\n",
      "('iteration: ', 10, ' loss: ', 1.449616)\n",
      "('iteration: ', 15, ' loss: ', 1.0782657)\n",
      "('iteration: ', 20, ' loss: ', 0.70797634)\n",
      "('iteration: ', 25, ' loss: ', 0.41246977)\n",
      "('iteration: ', 30, ' loss: ', 0.2432205)\n",
      "('iteration: ', 35, ' loss: ', 0.144933)\n",
      "('iteration: ', 40, ' loss: ', 0.086883694)\n",
      "('iteration: ', 45, ' loss: ', 0.05280648)\n",
      "('iteration: ', 50, ' loss: ', 0.033164337)\n",
      "('iteration: ', 55, ' loss: ', 0.022017434)\n",
      "('iteration: ', 60, ' loss: ', 0.01565735)\n",
      "('iteration: ', 65, ' loss: ', 0.011823485)\n",
      "('iteration: ', 70, ' loss: ', 0.009352837)\n",
      "('iteration: ', 75, ' loss: ', 0.007679077)\n",
      "('iteration: ', 80, ' loss: ', 0.0065005156)\n",
      "('iteration: ', 85, ' loss: ', 0.005637345)\n",
      "('iteration: ', 90, ' loss: ', 0.004979857)\n",
      "('iteration: ', 95, ' loss: ', 0.0044613923)\n",
      "('iteration: ', 100, ' loss: ', 0.0040409495)\n",
      "('iteration: ', 105, ' loss: ', 0.003692043)\n",
      "('iteration: ', 110, ' loss: ', 0.003396743)\n",
      "('iteration: ', 115, ' loss: ', 0.0031427261)\n",
      "('iteration: ', 120, ' loss: ', 0.0029212951)\n",
      "('iteration: ', 125, ' loss: ', 0.002726174)\n",
      "('iteration: ', 130, ' loss: ', 0.002552779)\n",
      "('iteration: ', 135, ' loss: ', 0.0023975773)\n",
      "('iteration: ', 140, ' loss: ', 0.0022578207)\n",
      "('iteration: ', 145, ' loss: ', 0.0021313555)\n",
      "('iteration: ', 150, ' loss: ', 0.0020163595)\n",
      "('iteration: ', 155, ' loss: ', 0.0019113725)\n",
      "('iteration: ', 160, ' loss: ', 0.0018152358)\n",
      "('iteration: ', 165, ' loss: ', 0.001726847)\n",
      "('iteration: ', 170, ' loss: ', 0.0016454252)\n",
      "('iteration: ', 175, ' loss: ', 0.0015700853)\n",
      "('iteration: ', 180, ' loss: ', 0.0015003062)\n",
      "('iteration: ', 185, ' loss: ', 0.0014354811)\n",
      "('iteration: ', 190, ' loss: ', 0.0013751041)\n",
      "('iteration: ', 195, ' loss: ', 0.0013188045)\n",
      "('iteration: ', 200, ' loss: ', 0.0012661774)\n",
      "('iteration: ', 205, ' loss: ', 0.00121697)\n",
      "('iteration: ', 210, ' loss: ', 0.0011706916)\n",
      "('iteration: ', 215, ' loss: ', 0.0011273095)\n",
      "('iteration: ', 220, ' loss: ', 0.001086477)\n",
      "('iteration: ', 225, ' loss: ', 0.0010479572)\n",
      "('iteration: ', 230, ' loss: ', 0.0010116235)\n",
      "('iteration: ', 235, ' loss: ', 0.0009773497)\n",
      "('iteration: ', 240, ' loss: ', 0.00094483874)\n",
      "('iteration: ', 245, ' loss: ', 0.0009140658)\n",
      "('iteration: ', 250, ' loss: ', 0.00088491256)\n",
      "('iteration: ', 255, ' loss: ', 0.00085725193)\n",
      "('iteration: ', 260, ' loss: ', 0.00083094847)\n",
      "('iteration: ', 265, ' loss: ', 0.0008059599)\n",
      "('iteration: ', 270, ' loss: ', 0.00078212516)\n",
      "('iteration: ', 275, ' loss: ', 0.00075939344)\n",
      "('iteration: ', 280, ' loss: ', 0.000737765)\n",
      "('iteration: ', 285, ' loss: ', 0.0007170786)\n",
      "('iteration: ', 290, ' loss: ', 0.0006973515)\n",
      "('iteration: ', 295, ' loss: ', 0.00067844766)\n",
      "('iteration: ', 300, ' loss: ', 0.00066041836)\n",
      "('iteration: ', 305, ' loss: ', 0.0006431022)\n",
      "('iteration: ', 310, ' loss: ', 0.0006265078)\n",
      "('iteration: ', 315, ' loss: ', 0.0006106098)\n",
      "('iteration: ', 320, ' loss: ', 0.0005953401)\n",
      "('iteration: ', 325, ' loss: ', 0.00058072456)\n",
      "('iteration: ', 330, ' loss: ', 0.0005665674)\n",
      "('iteration: ', 335, ' loss: ', 0.0005530986)\n",
      "('iteration: ', 340, ' loss: ', 0.00054002885)\n",
      "('iteration: ', 345, ' loss: ', 0.00052752846)\n",
      "('iteration: ', 350, ' loss: ', 0.00051544426)\n",
      "('iteration: ', 355, ' loss: ', 0.0005038189)\n",
      "('iteration: ', 360, ' loss: ', 0.0004926184)\n",
      "('iteration: ', 365, ' loss: ', 0.00048181732)\n",
      "('iteration: ', 370, ' loss: ', 0.00047133904)\n",
      "('iteration: ', 375, ' loss: ', 0.0004612943)\n",
      "('iteration: ', 380, ' loss: ', 0.0004515129)\n",
      "('iteration: ', 385, ' loss: ', 0.00044212257)\n",
      "('iteration: ', 390, ' loss: ', 0.00043300414)\n",
      "('iteration: ', 395, ' loss: ', 0.0004242428)\n",
      "('iteration: ', 400, ' loss: ', 0.00041569385)\n",
      "('iteration: ', 405, ' loss: ', 0.00040744245)\n",
      "('iteration: ', 410, ' loss: ', 0.0003994716)\n",
      "('iteration: ', 415, ' loss: ', 0.00039169623)\n",
      "('iteration: ', 420, ' loss: ', 0.00038420997)\n",
      "('iteration: ', 425, ' loss: ', 0.0003769277)\n",
      "('iteration: ', 430, ' loss: ', 0.00036988352)\n",
      "('iteration: ', 435, ' loss: ', 0.00036302634)\n",
      "('iteration: ', 440, ' loss: ', 0.00035638182)\n",
      "('iteration: ', 445, ' loss: ', 0.0003499158)\n",
      "('iteration: ', 450, ' loss: ', 0.00034367086)\n",
      "('iteration: ', 455, ' loss: ', 0.00033755344)\n",
      "('iteration: ', 460, ' loss: ', 0.00033168268)\n",
      "('iteration: ', 465, ' loss: ', 0.00032590545)\n",
      "('iteration: ', 470, ' loss: ', 0.0003203068)\n",
      "('iteration: ', 475, ' loss: ', 0.00031485266)\n",
      "('iteration: ', 480, ' loss: ', 0.00030956868)\n",
      "('iteration: ', 485, ' loss: ', 0.00030442927)\n",
      "('iteration: ', 490, ' loss: ', 0.00029940892)\n",
      "('iteration: ', 495, ' loss: ', 0.00029449913)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[6 5 3 3 4 4 2 7 8 9 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "epochs=500\n",
    "plot_loss=[]\n",
    "num_hidden=24  #？？？\n",
    "num_steps=X.shape[1]\n",
    "dict_length=len(small_dict)\n",
    "batch_size=2  #？\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## Make Variables\n",
    "variables_dict = {\n",
    "    \"weights1\":tf.Variable(tf.truncated_normal([num_hidden,dict_length],stddev=1.0,dtype=tf.float32),name=\"weights1\"),\n",
    "    \"biases1\": tf.Variable(tf.truncated_normal([dict_length],stddev=1.0,dtype=tf.float32), name=\"biases1\")}\n",
    "\n",
    "# Create input data\n",
    "X_one_hot=tf.nn.embedding_lookup(np.identity(dict_length), X) #[batch,num_steps,dictionary_length][2,6,7]\n",
    "y=np.zeros((batch_size,num_steps),dtype=np.int32)\n",
    "y[:,:-1]=X[:,1:]  #写的好，往后移一位\n",
    "y_one_hot=tf.unstack(tf.nn.embedding_lookup(np.identity(dict_length), y),num_steps,1) #[batch,num_steps,dictionary_length][2,6,7]\n",
    "\n",
    "y_target_reshape=tf.reshape(y_one_hot,[batch_size*num_steps,dict_length])\n",
    "\n",
    "#Create our LSTM\n",
    "cell = tf.contrib.rnn.LSTMCell(num_units=num_hidden, state_is_tuple=True)\n",
    "\n",
    "outputs, last_states = tf.contrib.rnn.static_rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float32,\n",
    "    inputs=tf.unstack(tf.to_float(X_one_hot),num_steps,1))\n",
    "\n",
    "output_reshape=tf.reshape(outputs, [batch_size*num_steps,num_hidden]) #[12==batch_size*num_steps,num_hidden==12]\n",
    "pred=tf.matmul(output_reshape, variables_dict[\"weights1\"]) +variables_dict[\"biases1\"]\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_target_reshape))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "plot_loss=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)        \n",
    "        for i in range(epochs):\n",
    "            loss,_,y_target,y_pred,output=sess.run([cost,optimizer,y_target_reshape,pred,outputs])\n",
    "            plot_loss.append([loss])\n",
    "\n",
    "            if i% 5 ==0:\n",
    "                print(\"iteration: \",i,\" loss: \",loss)\n",
    "                \n",
    "        print(y_target)\n",
    "        print(np.argmax(y_pred,1))          \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 已看到这 2 个句子 10 次。每次看到一个新单词时，都会尝试预测下一个单词。TensorFlow显示这些预测中的“损失”或误差约为 2.15。我们来看看使用样本句子会得出怎样结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence\n",
      "['my', 'cat', 'sleeps', 'on', 'my', 'bed', 'EOS']\n",
      "Predicted Words\n",
      "['cat', 'sleeps', 'on', 'my', 'bed', 'EOS', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "#Lets look at one input data point at each step and its prediction\n",
    "print(\"Input Sentence\")\n",
    "sn=0 #The sentence number\n",
    "print([small_dict[ind] for ind in X[sn,:]])\n",
    "print(\"Predicted Words\")\n",
    "print([small_dict[ind] for ind in np.argmax(y_pred[sn::2],1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sense of the output above, each \"Predicted Word\" was predicted to follow the corresponding word in the \"Input Sentence\". Eg. the first \"Predicted Word\" was predicted to follow the input word, \"My\", and the second predicted word was predicted to follow the two words, \"My cat.\"\n",
    "\n",
    "我们是否可以开始预测句子？至少能否预测出训练用的句子？通过将句子的第一个单词传递到预测变量，结果应该是我们的原始句子。发生了什么？\n",
    "\n",
    "### Improving Performance  \n",
    "#### Study More\n",
    "\n",
    "\n",
    "尝试将上述代码块中的迭代次数增加到 300。这将如何影响神经网络预测原始句子的能力？\n",
    "\n",
    "Note that increased training time still does help improve performance. However, remember that we're still working with a toy dataset. \n",
    "\n",
    "#### Deeper Networks\n",
    "\n",
    "虽然能够完美地预测出小样本中的句子，但我们接下来将采用更复杂的示例。我们来看看现有的可以影响性能的一些手段：网络的深度和称为“dropout”的运算。\n",
    "\n",
    "更深的模型能够表示更复杂的函数。为了在 TensorFlow 中构建一个更深的模型，我们可以在循环中创建自己的层。\n",
    "\n",
    "我们来训练一个包含 2 个和 4 个层的 RNN。您需要设置什么参数来更改 RNN 中的层数？如需获取提示，请将鼠标指针悬停在[此处](#answer1 \"num_layers=2 or num_layer=4. This is used in the 'for' loop where lstm_cells are created\")。\n",
    "\n",
    "Dropout 会要求您的模型在训练时“忘记”一些参数，从而提高模型的泛化能力。要查看在何处调整 dropout 值，请将鼠标指针悬停在[此处](#answer2 \"dropout = ___, where 1.0 = none -remember everything and 0.0 = all -remember nothing. This is implemented here: lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell,input_keep_prob=dropout,output_keep_prob=dropout)\")。\n",
    "\n",
    "对这两项进行试验，以确定是否可以提高性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iteration: ', 0, ' loss: ', 2.5035634)\n",
      "('iteration: ', 25, ' loss: ', 1.3529713)\n",
      "('iteration: ', 50, ' loss: ', 0.852092)\n",
      "('iteration: ', 75, ' loss: ', 0.6073251)\n",
      "('iteration: ', 100, ' loss: ', 0.4819387)\n",
      "('iteration: ', 125, ' loss: ', 0.29846668)\n",
      "('iteration: ', 150, ' loss: ', 0.2039622)\n",
      "('iteration: ', 175, ' loss: ', 0.12794822)\n",
      "('iteration: ', 200, ' loss: ', 0.10972194)\n",
      "('iteration: ', 225, ' loss: ', 0.13709183)\n",
      "('iteration: ', 250, ' loss: ', 0.057982497)\n",
      "('iteration: ', 275, ' loss: ', 0.07536502)\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[6 5 3 3 4 4 2 7 8 9 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Now let's try multiple layers \n",
    "plot_loss2=[]\n",
    "num_hidden=24\n",
    "num_steps=X.shape[1]\n",
    "dict_length=len(small_dict)\n",
    "batch_size=2\n",
    "num_layers=4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "## Make Variables\n",
    "variables_dict = {\n",
    "    \"weights1\":tf.Variable(tf.truncated_normal([num_hidden,dict_length],stddev=1.0,dtype=tf.float32),name=\"weights1\"),\n",
    "    \"biases1\": tf.Variable(tf.truncated_normal([dict_length],stddev=1.0,dtype=tf.float32), name=\"biases1\")}\n",
    "\n",
    "\n",
    "# Create input data\n",
    "#small_dict=['EOS','i','will','walk','the','dog','cat','run']\n",
    "#X=np.array([[1,2,7,4,5,0],[1,2,3,4,6,0]],dtype=np.int32)  \n",
    "X_one_hot=tf.nn.embedding_lookup(np.identity(dict_length), X) \n",
    "y=np.zeros((batch_size,num_steps),dtype=np.int32)\n",
    "y[:,:-1]=X[:,1:]\n",
    "y_one_hot=tf.unstack(tf.nn.embedding_lookup(np.identity(dict_length), y),num_steps,1) \n",
    "y_target_reshape=tf.reshape(y_one_hot,[batch_size*num_steps,dict_length])\n",
    "dropout = 0.85\n",
    "\n",
    "\n",
    "##################### Create a multilayer RNN ####################\n",
    "layer_cell=[]\n",
    "for _ in range(num_layers):\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(num_units=num_hidden, state_is_tuple=True)\n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell,\n",
    "                                          input_keep_prob=dropout,\n",
    "                                          output_keep_prob=dropout)\n",
    "    layer_cell.append(lstm_cell)\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell(layer_cell, state_is_tuple=True)\n",
    "outputs, last_states = tf.contrib.rnn.static_rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float32,\n",
    "    inputs=tf.unstack(tf.to_float(X_one_hot),num_steps,1))\n",
    "\n",
    "output_reshape=tf.reshape(outputs, [batch_size*num_steps,num_hidden])\n",
    "pred=tf.matmul(output_reshape, variables_dict[\"weights1\"]) +variables_dict[\"biases1\"]\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_target_reshape))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        for i in range(300):\n",
    "            loss,_,y_target,y_pred,output=sess.run([cost,optimizer,y_target_reshape,pred,outputs])\n",
    "            plot_loss2.append([loss])\n",
    "            \n",
    "            if i% 25 ==0:\n",
    "                print(\"iteration: \",i,\" loss: \",loss)\n",
    "                \n",
    "        print(y_target)\n",
    "        print(np.argmax(y_pred,1))         \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 比较我们的单层 RNN 与多层 RNN 的损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49e5886790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(plot_loss,'r.')\n",
    "plt.plot(plot_loss2,'b--')\n",
    "plt.legend([\"1-Layer LSTM\",\"Multi-Layer LSTM\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.title(\"Loss During Training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的模型也可以完成这两个句子，但同时对语言的其余部分一无所知。（这就像我们学习了一首歌的两行内容一样。）相反，如果改为努力构建对语言的一般理解，我们会严重地过拟合语料库。增加模型的复杂性（深度）可以学习更复杂的[语料库](#corpora \"actually corpora\")，但可能会导致过拟合。Dropout 是用于减少过拟合的一种方法。在我们努力学习完整类型的语言（即，说明）时，需要牢记这些策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 MSCOCO 说明训练 RNN\n",
    "现在，我们将使用 [Microsoft Common Objects in Context](http://mscoco.org/) (MSCOCO)图像描述来训练 RNN ，理解这个图片的描述。以下单元显示了一种对数据进行读取和格式设置，并将其输入 TensorFlow 的方法。首先，我们将读取描述图片的文件，然后将文件中的文字内容删除标点并进行训练。由于时间限制，我们不会将完整数据集用于此训练。但是，可以很容易地更改代码内容，并使用更多的数据集内容或完整数据集进行训练。您是否有简单方法可完成此操作？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import inspect\n",
    "import time\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "#import reader\n",
    "import collections\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "num_steps=20\n",
    "## Read Training files\n",
    "with open(\"/dli/data/mdt/mscoco/captions_train2014.json\") as data_file:\n",
    "         data=json.load(data_file)\n",
    "\n",
    "TotalNumberofCaptions=len(data['annotations'])\n",
    "\n",
    "sentences=[]\n",
    "\n",
    "##Create a list of all of the sentences.\n",
    "for i in range(TotalNumberofCaptions):\n",
    "        sentences+=[re.sub('[^A-Za-z0-9]+',' ',data['annotations'][i]['caption']).lower()]  #正则表达式\n",
    "\n",
    "TotalWordList=[]\n",
    "for i in range(TotalNumberofCaptions):\n",
    "        TotalWordList+=re.sub('[^A-Za-z0-9]+',' ',data['annotations'][i]['caption']).lower().split()\n",
    "\n",
    "#Determine number of distinct words \n",
    "distinctwords=collections.Counter(TotalWordList)\n",
    "#Order words \n",
    "count_pairs = sorted(distinctwords.items(), key=lambda x: (-x[1], x[0])) #ascending order\n",
    "\n",
    "words, occurence = list(zip(*count_pairs))\n",
    "DictionaryLength=occurence.index(4) #index for words that occur 4 times or less\n",
    "words=['PAD','UNK','EOS']+list(words[:DictionaryLength])\n",
    "word_to_id=dict(zip(words, range(len(words))))\n",
    "#Tokenize Sentence\n",
    "Tokenized=[]\n",
    "for full_words in sentences:\n",
    "        EmbeddedSentence=[word_to_id[word] for word in full_words.split() if word in word_to_id]+[word_to_id['EOS']]\n",
    "        #Pad sentences that are shorter than the number of steps \n",
    "        if len(EmbeddedSentence)<num_steps:\n",
    "            b=[word_to_id['PAD']]*num_steps\n",
    "            b[:len(EmbeddedSentence)]=EmbeddedSentence\n",
    "        if len(EmbeddedSentence)>num_steps:\n",
    "            b=EmbeddedSentence[:num_steps]\n",
    "        if len(b)==EmbeddedSentence:\n",
    "            b=EmeddedSentence\n",
    "        b=[word_to_id['UNK'] if x>=DictionaryLength else x for x in b] #turn all words used 4 times or less to 'UNK'\n",
    "        #print(b)\n",
    "        Tokenized+=[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以针对这些描述进行“标记化”，或者将每个单词转换为一个数字（根据流行度按降序排序）。我们还有不同的句子长度，因此，为了创建标准的输入和输出张量，我们使用 0 填充短句子并截断了长句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 142, 508, 9, 619, 415, 276, 57, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[142, 508, 9, 619, 415, 276, 57, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Number of words in this dictionary 8768\n"
     ]
    }
   ],
   "source": [
    "############################################# Parameters #####################################################\n",
    "\n",
    "num_hidden=256\n",
    "num_steps=20\n",
    "dict_length=len(words)\n",
    "batch_size=4\n",
    "\n",
    "\n",
    "## Create labels\n",
    "Label=[]\n",
    "for caption in Tokenized:\n",
    "    Label+=[caption[1:]+[word_to_id['PAD']]]\n",
    "\n",
    "NumberofCasestoEvaluate=20\n",
    "TrainingInputs=Tokenized[:NumberofCasestoEvaluate]\n",
    "LabelInputs=Label[:NumberofCasestoEvaluate]\n",
    "\n",
    "#Print out some variables \n",
    "print(TrainingInputs[0])\n",
    "print(LabelInputs[0])\n",
    "print(\"Number of words in this dictionary\", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以看到两方面的内容：\n",
    "\n",
    "1. [标签](#labels \"labels are the outputs that we want our network to generate\")是训练集中的下一个“token”（单词的标记）。\n",
    "2. 字典更大。 \n",
    "\n",
    "我们将分 4 批将数据输入网络，以便进一步充分利用并行处理和 GPU计算，降低计算时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our input queue\n",
    "def data_input_queue(TrainingInputs, LabelInputs, num_steps):\n",
    "    train_input_queue = tf.train.slice_input_producer(                 #并行处理\n",
    "                                    [TrainingInputs, LabelInputs],\n",
    "                                    shuffle=True)\n",
    "\n",
    "    ##Set our train data and label input shape for the queue\n",
    "    TrainingInput=train_input_queue[0]\n",
    "    LabelInput=train_input_queue[1]\n",
    "    TrainingInput.set_shape([num_steps])\n",
    "    LabelInput.set_shape([num_steps])\n",
    "    min_after_dequeue=100000\n",
    "    capacity = min_after_dequeue + 3 * batch_size \n",
    "    #input_x, target_y\n",
    "    train_x, train_y = tf.train.batch([TrainingInput, LabelInput],           #与上面一起用\n",
    "                                                 batch_size=batch_size ,\n",
    "                                                 capacity=capacity,\n",
    "                                                 num_threads=4)\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，您已准备好使用 MSCOCO 说明训练 RNN。可以使用任意层数进行试验，并再次执行 dropout。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 loss:  8.478596\n",
      "iteration:  100 loss:  0.110077426\n",
      "iteration:  200 loss:  0.089920625\n",
      "iteration:  300 loss:  0.05734334\n",
      "iteration:  400 loss:  0.111818396\n",
      "iteration:  500 loss:  0.09395734\n",
      "iteration:  600 loss:  0.102980815\n",
      "iteration:  700 loss:  0.08803368\n",
      "iteration:  800 loss:  0.10325841\n",
      "iteration:  900 loss:  0.10161339\n",
      "iteration:  1000 loss:  0.06951494\n",
      "iteration:  1100 loss:  0.1013256\n",
      "iteration:  1200 loss:  0.10544834\n",
      "iteration:  1300 loss:  0.1082193\n",
      "iteration:  1400 loss:  0.11626966\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "num_layers=1\n",
    "dropout = 1.0\n",
    "\n",
    "loss_mscoco=[]\n",
    "#######################################################################################################\n",
    "TrainingInputs=Tokenized[:NumberofCasestoEvaluate]\n",
    "LabelInputs=Label[:NumberofCasestoEvaluate]\n",
    "\n",
    "\n",
    "variables_dict = {\n",
    "    \"weights_mscoco\":tf.Variable(tf.truncated_normal([num_hidden,dict_length],\n",
    "                                                     stddev=1.0,dtype=tf.float32),name=\"weights_mscoco\"),\n",
    "    \"biases_mscoco\": tf.Variable(tf.truncated_normal([dict_length],\n",
    "                                                     stddev=1.0,dtype=tf.float32), name=\"biases_mscoco\")}\n",
    "\n",
    "\n",
    "# Create input data\n",
    "train_x, train_y =data_input_queue(TrainingInputs, LabelInputs, num_steps)\n",
    "mscoco_dict=words\n",
    "X_one_hot=tf.nn.embedding_lookup(np.identity(dict_length), train_x) #[batch,num_steps,dictionary_length]\n",
    "y_one_hot=tf.unstack(tf.nn.embedding_lookup(np.identity(dict_length), train_y),num_steps,1)#[batch,num_steps,dictionary_length]\n",
    "y_target_reshape=tf.reshape(y_one_hot,[batch_size*num_steps,dict_length])\n",
    "\n",
    "input_keep_prob=dropout\n",
    "output_keep_prob=dropout\n",
    "\n",
    "#Create a multilayer RNN\n",
    "\n",
    "layer_cell=[]\n",
    "for _ in range(num_layers):\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(num_units=num_hidden, state_is_tuple=True)\n",
    "    ############# add dropout #########################\n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell,\n",
    "                                          input_keep_prob=dropout,\n",
    "                                          output_keep_prob=dropout)\n",
    "    layer_cell.append(lstm_cell)\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell(layer_cell, state_is_tuple=True)\n",
    "outputs, last_states = tf.contrib.rnn.static_rnn(\n",
    "    cell=lstm_cell,\n",
    "    dtype=tf.float32,\n",
    "    inputs=tf.unstack(tf.to_float(X_one_hot),num_steps,1))\n",
    "\n",
    "output_reshape=tf.reshape(outputs, [batch_size*num_steps,num_hidden])\n",
    "pred=tf.matmul(output_reshape, variables_dict[\"weights_mscoco\"]) +variables_dict[\"biases_mscoco\"]\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_target_reshape))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost,aggregation_method = tf.AggregationMethod.EXPERIMENTAL_TREE)\n",
    "\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())    \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        for i in range(1500):\n",
    "            x_input,y_input=sess.run([train_x, train_y])\n",
    "            loss,_,y_target,x_input,y_input,y_pred=sess.run([cost,optimizer,y_target_reshape,train_x, train_y,pred])\n",
    "            loss_mscoco.append([loss])\n",
    "            if i% 100==0:\n",
    "                print(\"iteration: \",i, \"loss: \",loss)  \n",
    "        print(\"Done Training\")\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence\n",
      "[u'a', u'graffiti', u'ed', u'stop', u'sign', u'across', u'the', u'street', u'from', u'a', u'red', u'car', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Target\n",
      "[u'graffiti', u'ed', u'stop', u'sign', u'across', u'the', u'street', u'from', u'a', u'red', u'car', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Predicted words\n",
      "[u'panoramic', u'ed', u'stop', u'sign', u'across', u'the', u'street', u'from', u'a', u'red', u'car', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"
     ]
    }
   ],
   "source": [
    "#Lets look at one input data point and its prediction\n",
    "print(\"Input Sentence\")\n",
    "batch_element=2\n",
    "print([words[ind] for ind in x_input[batch_element,:]])\n",
    "print(\"Target\")\n",
    "print([words[ind] for ind in y_input[batch_element,:]])\n",
    "print(\"Predicted words\")\n",
    "print([words[ind] for ind in np.argmax(y_pred[batch_element::batch_size],1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们该怎么做？我们已学习使用 RNN 根据前一个单词预测下一个单词， 及RNN 对语言的理解。\n",
    "通过部署此模型，我们可以解决什么类型的问题？\n",
    "如果掌握了能够很好地完成这项工作的技能，我们可以做一些有意思的事情，比如模仿某人的书写风格、根据过去的表现生成股票市场报价预测或者在文本消息中提供后续单词建议。\n",
    "目前为止，我们受限于[真值](#gt \"actual next word at every timestep\") 是在整个网络中传递这一事实。如果我们生成不止一个单词，表现将会很糟糕。\n",
    "\n",
    "要让我们的网络生成完整的句子，一种方法是提供一些上下文。在下一节中，我们将以图像的形式为网络提供默想，也就是要书写的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 参考资料\n",
    "[1] Imanol Schlab. TensorFlow Input Pipeline Example. http://ischlag.github.io/\n",
    "\n",
    "[2] Denny Britz. Practical Examples for RNNs in TensorFlow https://github.com/dennybritz/tf-rnn\n",
    "\n",
    "[3]Lin, Tsung-Yi, et al. \"Microsoft coco: Common objects in context.\" European Conference on Computer Vision. Springer International Publishing, 2014."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
