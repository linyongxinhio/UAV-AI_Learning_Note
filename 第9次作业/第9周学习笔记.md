# 循环神经网络RNN

## 一.基本概念

### <一> 循环神经网络RNN

#### 1.为什么引入RNN？

虽然RNN跟之前学习的前馈神经网络很相似，但是它的引入在一定程度上更好处理具有前后关系的序列信息。比如，当我们在理解一句话意思时，孤立的理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个序列； 当我们处理视频的时候，我们也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个序列。所以为了解决一些这样类似的问题，能够更好的处理序列的信息，RNN就诞生了。

#### 2.RNN的基本结构

![1545317896283](.\pictures\1545317896283.png)

上面这张图X代表输入层，A代表隐藏层，h代表输出层。**这里的A虽然展开了，但是还是属于同一个A，只是在时间序列上展开了，为了更好的展示内部工作流程而画的。这里想了很久才想明白。**

![1545318047144](.\pictures\1545318047144.png)

这张图可以很清晰看到RNN在时间维度的展开，每个T对应着同样的结构，不要把时间维度搞混了。但这张图的维度不太好理解，在下面LSTM的理解中可以进一步理解。

### <二> 长短记忆期单元LSTM

![1545361519833](.\pictures\1545361519833.png)

#### 难点一. tf.nn.rnn_cell.LSTMCell中num_unit代表的含义？

这里想了很久才想明白，上面这张图讲的特别清晰。**不要理解为num_unit代表cell的个数，实际上这个参数是代表每个小框（上图虚线框）里面神经元的个数。**一个LSTM cell里面包含四个门，分别是学习门、遗忘门、记忆门和输出门。

##### **1.学习门**

![img](file:///C:\Users\linyongxin\AppData\Roaming\Tencent\Users\627269220\TIM\WinTemp\RichOle\Y~A%F[IE}L]G8`]HS75``2A.png)

![1545362799032](.\pictures\1545362799032.png)

> 从学习门的结构中我们可以看到有一个tanh层和一个sigmoid层，分别对应上彩色图的红色节点的小框和黄色节点的小框。首先是上一时刻的输出和这一时刻的X结合在一起作为输入，然后经过tanh层得到Nt和经过sigmoid层得到it，最后通过乘法运算把两者结合起来，结果为Nt * it。实际上，通过tanh将短期记忆和当前事件结合得到Nt，并乘以遗忘因子it得Nt * it，而遗忘因子it来自于短期记忆和当前事件的另一个组合。这就是学习门的工作原理。**需要注意的是，经过这个门得到的结果维度和num_unit一致，比如上面彩色大图是num_unit=128，那么学习门输出的结果就是128维度。同时还要注意，学习门不是仅仅指tanh层和sigmoid层，而是如上面手写图所示才为一个门，门里面包含了这两层和其相关运算。**

##### **2.遗忘门**

![1545365919672](.\pictures\1545365919672.png)



![1545362697187](.\pictures\1545362697187.png)

> 同理，我们可以把这张手写的图和上面彩色图进行相互对应，可以发现同样的规律。只不过遗忘门中只包含一个sigmoid层，对应彩色图的紫色部分。遗忘门的工作原理是长期记忆LTM（t-1） * ft ，ft是遗忘因子，来自短期记忆和当前事件的组合。

##### 3.记忆门

![1545366190726](.\pictures\1545366190726.png)

![1545362721083](.\pictures\1545362721083.png)

> 记忆门是根据遗忘门和学习门的结果进行加运算，对应彩色图的“+”，绿色部分C(t)就是其输出，也就是上面手写图的LTMt。记忆门的工作原理是将遗忘门输出的长期记忆和学习门学的到的短期记忆进行组合。

##### 4.输出门

![1545366660170](.\pictures\1545366660170.png)

> 输出门是把遗忘门的结果经过tanh层（彩色图黄色节点小框）和输入值经过sigmoid层（彩色图的蓝色节点小框）进行乘法运算。

##### 5.总体结构 

![1545362763007](.\pictures\1545362763007.png)

![1545311852789](.\pictures\1545311852789.png)

---

#### 难点二. LSTM中时间序列展开的理解？

![1545311795856](.\pictures\1545311795856.png)

一般我们查到的资料都是如上图这样解释LSTM，实际上这里的A是指的同一个cell，只是对应不同的时刻而把它展开了，方便理解，**所以不要错误地以为这是不同的LSTM cell**。

## 二.项目分析

### <一> 使用LSTM实现sin函数的预测

#### 1.完整代码

```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

train_numbers = 10000  # 训练数据的个数
test_numbers = 1000  # 测试数据的个数
sin_gap = 0.01  # sin函数的采样间隔
timesteps = 20  # 每个训练样本的长度

# 生成训练数据和标签，X代表训练数据的输入数据，Y代表训练数据的标签
# timesteps=20代表每隔20个数据，预测一个数据，跟标签Y比对
def generate_data(seq):
    X = []
    Y = []
    #  生成X是一个二维数组，即20元素的一个序列，N个序列
    for i in range(len(seq) - timesteps -1):
        X.append(seq[i : i+timesteps])  #每行存储timesteps个数据，代表输入数据  
        Y.append(seq[i+timesteps])  #输出Y是一维数组，对应X中每一行的最后数据的下一个数据，即标签

    return np.array(X, dtype=np.float32), np.array(Y, dtype=np.float32)

# 构造迭代器，获取一个batch_size大小的数据  ,每次batch为64组数据
def get_batches(X, y, batch_size=64):
    for i in range(0, len(X), batch_size):
        begin_i = i
        end_i = i + batch_size if (i+batch_size) < len(X) else len(X)

        yield X[begin_i:end_i,:], y[begin_i:end_i]

test_start = train_numbers*sin_gap  # 10000*0.01=100
test_end = test_start + test_numbers*sin_gap  # 100+1000*0.01=110

# 即采用10000个生成训练数据
train_x, train_y = generate_data( np.sin(np.linspace(0, test_start, train_numbers)))  
#采用1000个点生成测试数据，并且不能与训练数据重复
test_x, test_y = generate_data(np.sin(np.linspace(test_start, test_end, test_numbers)))

lstm_size = 20  # 
lstm_layers = 2
batch_size = 64

# dynamic_rnn需要三维的数据输入，即64*20*1，1代表是输入单个时间步长下输入数据维度为1
x = tf.placeholder(tf.float32, [None, timesteps, 1], name='input_x')
y = tf.placeholder(tf.float32, [None, 1], name='input_y')
keep_prob = tf.placeholder(tf.float32, name='keep_prob')

lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)  # 有lstm_size个单元
drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)  # 添加dropout

# 一层不够，就多来几层
def lstm_cell():
    return tf.nn.rnn_cell.LSTMCell(lstm_size)
cell = tf.contrib.rnn.MultiRNNCell([ lstm_cell() for _ in range(lstm_layers)])  

# 进行前向反馈过程，得到隐层的输出和最后的隐状态
outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)
outputs = outputs[:,-1,:]  # 取时间维度上取最后一个时间步长的数据

# 定义输出层, 输出值[-1,1]，因此激活函数用tanh
predictions = tf.contrib.layers.fully_connected(outputs, 1, activation_fn=tf.tanh)#采用全连接层
# 定义损失函数
cost = tf.losses.mean_squared_error(y, predictions)
# 定义优化步骤
optimizer = tf.train.AdamOptimizer().minimize(cost)

# 训练并创建会话
epochs = 50
session = tf.Session()
with session.as_default() as sess:
    # 初始化变量
    tf.global_variables_initializer().run()

    iteration = 1

    for e in range(epochs):
        for xs, ys in get_batches(train_x, train_y, batch_size):
            '''
            相当于next（batch），迭代器
            xs[:,:,None] 增加一个维度，例如[64, 20] ==> [64, 20, 1]，为了对应输入
            同理 ys[:,None]
            '''

            feed_dict = { x:xs[:,:,None], y:ys[:,None], keep_prob:.5 }  

            loss, _ = sess.run([cost, optimizer], feed_dict=feed_dict)

            if iteration % 100 == 0:
                print('Epochs:{}/{}'.format(e, epochs),
                      'Iteration:{}'.format(iteration),
                      'Train loss: {:.8f}'.format(loss))
            iteration += 1

# 可视化结果
with session.as_default() as sess:
    ## 测试结果
    feed_dict = {x:test_x[:,:,None], keep_prob:1.0}
    results = sess.run(predictions, feed_dict=feed_dict)
    plt.plot(results,'r', label='predicted')
    plt.plot(test_y, 'g--', label='real sin')
    plt.legend()
    plt.show()

```

#### 2.实验结果

损失函数的打印结果：

![1545356123093](.\pictures\1545356123093.png)

预测的sin函数和标签的比对结果：

![1545356203162](.\pictures\1545356203162.png)



#### 3.代码分析

```python
train_numbers = 10000  # 训练数据的个数
test_numbers = 1000  # 测试数据的个数
sin_gap = 0.01  # sin函数的采样间隔
timesteps = 20  # 每个训练样本的长度
```

> **train_numbers**代表训练数据的个数，**test_numbers**代表测试数据的个数，这两个变量后面生成数据会用到，这个项目的数据集是需要自己 生成的。
>
> **sin_gap**是sin函数的采样间隔，即采用周期/采用总数。
>
> **timesteps**是训练样本的长度，也就是每timesteps个数据预测一个数据。

---

```python
def generate_data(seq):
    X = []
    Y = []
    #  生成X是一个二维数组，即20元素的一个序列，N个序列
    for i in range(len(seq) - timesteps -1):
        X.append(seq[i : i+timesteps])  #  每行存储timesteps个数据，代表输入数据  
        Y.append(seq[i+timesteps])  # 对应X中每一行的输出结果，也是timesteps+2数据，即标签

    return np.array(X, dtype=np.float32), np.array(Y, dtype=np.float32)

test_start = train_numbers*sin_gap  # 10000*0.01=100
test_end = test_start + test_numbers*sin_gap  # 100+1000*0.01=110

# 即采用10000个生成训练数据
train_x, train_y = generate_data( np.sin(np.linspace(0, test_start, train_numbers)))  
#采用1000个点生成测试数据，并且不能与训练数据重复
test_x, test_y = generate_data(np.sin(np.linspace(test_start, test_end, test_numbers)))
```

> **generate_data**函数主要是生成训练数据和标签，传入序列seq，然后从这个序列里面生成训练数据集和训练数据集的标签。X代表训练数据集的输入数据，Y代表训练数据集的标签。
>
> **`for i in range(len(seq) - timesteps -1)`**这个循环语句主要是实现将seq的数据按照每timesteps个数据就存到X中的一行中，然后第timesteps+1个数据就存到Y中作为标签，所以只需要遍历len(seq) - timesteps -1个数即可。序列的第 i 项和后面的 timesteps -1 项合在一起作为输入，第 i + timesteps  项作为输出。这里的timesteps是20，所以每20个数据就作为输入，然后第21个数据就是输出的标签，用来后面预测时比对用的。而我们预测sin函数也是通过每20个数据预测一个数据来实现的。
>
> **test_start**代表测试集从哪个数据开始，即开始的位置。
>
> **test_end**代表测试集从哪个数据结束，即结束的位置。
>
> **numpy.linspace() **函数的格式为[start,stop,num]，其中start代表起始值，stop代表终止值（包含在内），
> num代表数列长度（默认为 50），这个函数可以创建一个等差序列。因为标准的循环神经网络模型预测的是离散的数值，所以需要将连续的 sin 函数曲线离散化。所谓离散化就是在一个给定的区间 [0,MAX] 内，通过有限个采样点模拟一个连续的曲线，即间隔相同距离取点。所以这里采用 numpy.linspace() 函数来实现离散化。

---

```python
lstm_size = 20  # LSTM的cell个数为20，可以理解为隐藏层有20个cell
lstm_layers = 2  # 有两层LSTM cell
batch_size = 64

# dynamic_rnn需要三维的数据输入，即64*20*1，1代表是输入单个时间步长下输入数据维度为1
x = tf.placeholder(tf.float32, [None, timesteps, 1], name='input_x')
y = tf.placeholder(tf.float32, [None, 1], name='input_y')  # y为二维数组
keep_prob = tf.placeholder(tf.float32, name='keep_prob')  # 设置dropout的概率
```

> **lstm_size**实际上时隐藏层中的lstm cell中各个层的神经元个数，也就是tanh层或者sigmoid层的神经元个数。在上面的LSTM难点一里面已经解释地很详细，所以这里地lstm_size=20代表sigmoid层和tanh层都含有20个神经元个数，同样这里的个数和最后输出的维度一致，输出也是20维度。
>
> **lstm_layers**代表的是有几层LSTM cell，这里我们设置为2层。

---

```python
# 有lstm_size个cell单元
lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)

# 添加dropout层
drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)

# 设置多层LSTM cell
def lstm_cell():
    return tf.nn.rnn_cell.LSTMCell(lstm_size)
cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(lstm_layers)]) #两层LSTM

# 进行前向反馈过程，得到隐层的输出和最后的隐状态
outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)
outputs = outputs[:,-1,:]  # 在时间维度上取最后一个时间步长的数据

# 定义输出层, 输出值[-1,1]，因此激活函数用tanh
# 采用全连接层
predictions = tf.contrib.layers.fully_connected(outputs, 1, activation_fn=tf.tanh)
# 定义损失函数
cost = tf.losses.mean_squared_error(y, predictions)
# 定义优化步骤
optimizer = tf.train.AdamOptimizer().minimize(cost)
```

> `lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)`是调用tensorflow来定义lstm_size个cell单元的lstm层。
>
> `tf.contrib.rnn.MultiRNNCell`用来定义多层的LSTM层，相当于传统MLP的多个隐藏层，每个隐藏层有多个神经元节点，每个节点对应这里的每个cell。`lstm_cell() for _ in range(lstm_layers)`这条语句就是通过for循环来调用lstm_cell()函数来实现多层LSTM的创建。其中的“**_**”代表变量，但是不需要保存，是python的一种写法。
>
> `outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)`这条语句可以得到前向反馈过程后的输出和最后的状态。然后我们只需要最后一个时间步长的数据，所以对outputs做了截取操作，即`outputs = outputs[:,-1,:]`
>
> **predictions,cost,optimizer**分别代表预测值，损失函数和优化器，这个和传统的MLP差不多。

---

```python
# 获取一个batch_size大小的数据  ,每次batch为64组数据
def get_batches(X, y, batch_size=64):
    for i in range(0, len(X), batch_size):
        begin_i = i
        end_i = i + batch_size if (i+batch_size) < len(X) else len(X)

        yield X[begin_i:end_i,:], y[begin_i:end_i]
```

> **关于python中的生成器和迭代器：**
>
> **1.生成器(generator)**
>
> 有时候我们不知道创建对象的长度，比如创建list，这个list受内存的限制，容量是有限的，同时如果我们只访问这个list 的前几个元素，那么list后面的空间就浪费了。因此，我们引入了生成器。在Python中，一边循环一边计算的机制，称为生成器(generator)。generator保存的是算法，每次调用`next(g)`，就计算g的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。但实际上我们一般用for循环来代替next。一般而言，我们只有把传统的函数里面的print函数改为yeild就可以变成generator。这样的generator的工作原理与函数不同，函数是顺序执行，遇到`return`语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用`next()`的时候执行，遇到`yield`语句返回，再次执行时从上次返回的`yield`语句处继续执行。**通过这样的机制我们就是可以实现batch的批处理过程。**
>
> **2.迭代器(Iterator)**
>
> - 凡是可作用于`for`循环的对象都是`Iterable`类型；
>
> - 凡是可作用于`next()`函数的对象都是`Iterator`类型，它们表示一个惰性计算的序列；
>
> - 集合数据类型如`list`、`dict`、`str`等是`Iterable`但不是`Iterator`，不过可以通过`iter()`函数获得一个`Iterator`对象。

### <二> 使用RNN训练文本模拟安娜卡列尼娜写作

### <三> 实现skip-gram词嵌入脚本

## 三.附录——手写笔记

![1545367464843](.\pictures\1545367464843.png)

![1545367480875](.\pictures\1545367480875.png)

![1545367506825](.\pictures\1545367506825.png)

![1545367524914](.\pictures\1545367524914.png)

![1545367546094](.\pictures\1545367546094.png)

![1545367565755](.\pictures\1545367565755.png)

![1545367589006](.\pictures\1545367589006.png)

![1545367663806](.\pictures\1545367663806.png)

![1545367692724](.\pictures\1545367692724.png)

